{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import re, string, unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from word2number import w2n\n",
    "from ast import literal_eval\n",
    "from nltk.corpus import wordnet\n",
    "import qgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1220834 entries, 0 to 1220833\n",
      "Data columns (total 2 columns):\n",
      "description_text     1220834 non-null object\n",
      "harmonized_number    1220834 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 18.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_text</th>\n",
       "      <th>harmonized_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[WOODWORKING, MACHINE, AND, SPARE, PARTS, H.S....</td>\n",
       "      <td>846591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[WOODWORKING, MACHINE, AND, SPARE, PARTS, PO, ...</td>\n",
       "      <td>846591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[STAND, ,, ZERO, CLEARANCE, THROAT, PLATE, ,, ...</td>\n",
       "      <td>846591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[., ., ., ., ., ., ., .]</td>\n",
       "      <td>846591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[., ., ., ., ., .]</td>\n",
       "      <td>846591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_text harmonized_number\n",
       "0  [WOODWORKING, MACHINE, AND, SPARE, PARTS, H.S....            846591\n",
       "1  [WOODWORKING, MACHINE, AND, SPARE, PARTS, PO, ...            846591\n",
       "2  [STAND, ,, ZERO, CLEARANCE, THROAT, PLATE, ,, ...            846591\n",
       "3                           [., ., ., ., ., ., ., .]            846591\n",
       "4                                 [., ., ., ., ., .]            846591"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('prepared_data_tokenized.csv',low_memory=False)\n",
    "df['description_text'] = df.description_text.apply(literal_eval)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "df['description_text'] = df['description_text'].apply(to_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "df['description_text'] = df['description_text'].apply(remove_non_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_num(words):\n",
    "    \"\"\"Convert all textual numbers to digits from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word\n",
    "        try:\n",
    "            new_word = str(w2n.word_to_num(word))\n",
    "        except:\n",
    "            pass\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "df['description_text'] = df['description_text'].apply(word_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alpha(words):\n",
    "    \"\"\"Remove non alpha in list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isalpha():\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "df['description_text'] = df['description_text'].apply(remove_non_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "df['description_text'] = df['description_text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "df['description_text'] = df['description_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, get_wordnet_pos(word))\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "df['description_text'] = df['description_text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_english(words):\n",
    "    \"\"\"Remove non english words in list of tokenized words\"\"\"\n",
    "    english = set(nltk.corpus.words.words())\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word in english:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "df['description_text'] = df['description_text'].apply(remove_non_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a21d9d96a74b82ac5401751cd97f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defauâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2['description_text'] = df2['description_text'].apply(lambda x: ' '.join(x))\n",
    "df2['description_text'] = df2['description_text'].str.replace(',', '').str.replace('[', '').str.replace(']', '')\n",
    "mf = pd.Series(' '.join(df2['description_text']).lower().split()).value_counts()\n",
    "qgrid.show_grid(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(words):\n",
    "    \"\"\"Remove noise from list of tokenized words\"\"\"\n",
    "    noise = ['hs','code','hts','invoice','pallet','kg','certify','po','pack','industry','office','expiration',\n",
    "                'voyage','cargo','clearance','date','onto','loading', 'de', 'appliance','en','ca','un',\n",
    "                'freight','package', 'load','shipper','qty', 'net','contain','container','order','number',\n",
    "                'weight','contract','carrier','shipment','dhl', 'notify','collect','shipper','certified',\n",
    "                'pc','forwarding','delivery','note', 'ref', 'packed', 'gross','product','loaded',\n",
    "                'piece','export','of','and','no','po','on','for','nw','number','article','classification',\n",
    "                'tariff','china','brazil','argentine','date','new','unpacked','limited','traffic','pay',\n",
    "                'ctn','nr','no','name','am','serial','ex','exceed','payable','regulate','fi','exclude',\n",
    "                'blk','gr','international','fca','due','eta','etd','accordance','deliver',\n",
    "                'stc','gross','order','pcs','total','per','the','prepaid','consist','distribution',\n",
    "                'plt','contain','equipment','capacity','class','white','description','approve',\n",
    "                'shipped','nos','ncm','tariff','category','ready','license','violation',\n",
    "                'country','count','nesoi','ncm','ruc','complete','id','quantity','regulation',\n",
    "                'destination','nac','pkg','declare','declared','fax','cargo','transportation',\n",
    "                'commercial','contact','nvocc','nbr', 'prepaid','brand','continuation',\n",
    "                'hc','mm','customer','orange','violet','rose','company',\n",
    "                'imo','sc','tsca','cm','hscode','harmless','applicable',\n",
    "                'po','ship','nw','y','pkg', 'esd','email','sc','pack','detail','transport',\n",
    "                'banq','origin','pa','charge','account','via',\n",
    "                'rate', 'package','certify','container', 'consignee','declare',\n",
    "                'purchase','payment','bill','abroad','express','certify',\n",
    "                'red','green','black','grey','blue','yellow','white','account','charge','local',\n",
    "                'date','id','name','item','customer','lot','duty','invoice','commodity',\n",
    "                'address','comply','say','mexico','canada','japan','uk','germany','france',\n",
    "                'shipping','exporter', \"import\", \"information\", \"declaration\",'supplier','release',\n",
    "                'loader','agreement','liability','compliant', 'registration','compliance','weigh',\n",
    "                'foreign', 'corporation','discharge','certificate','detention','logistics','vessel',\n",
    "                'transit','temperature','quality','transfer','impact','requirement','global','tax','reception',\n",
    "                'manufacturer','carriage','enterprise','trading','emergency','free','description','agreement','terminal',\n",
    "                'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
    "                ]\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in noise:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "df['description_text'] = df['description_text'].apply(remove_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1120838 entries, 0 to 1120837\n",
      "Data columns (total 2 columns):\n",
      "description_text     1120838 non-null object\n",
      "harmonized_number    1120838 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_text</th>\n",
       "      <th>harmonized_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[woodworking, machine, spare, part]</td>\n",
       "      <td>846591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[woodworking, machine, spare, part, spare, par...</td>\n",
       "      <td>846591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[stand, throat, plate, glide, pad]</td>\n",
       "      <td>846591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[garment, men, soccer, sock, soccer, sock, jun...</td>\n",
       "      <td>611595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[cover, connect, prestige]</td>\n",
       "      <td>611595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_text harmonized_number\n",
       "0                [woodworking, machine, spare, part]            846591\n",
       "1  [woodworking, machine, spare, part, spare, par...            846591\n",
       "2                 [stand, throat, plate, glide, pad]            846591\n",
       "3  [garment, men, soccer, sock, soccer, sock, jun...            611595\n",
       "4                         [cover, connect, prestige]            611595"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['description_text'].map(lambda d: len(d)) > 0]\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.drop(['index'],axis=1)\n",
    "\n",
    "df.to_csv('final_lemmatized.csv', index=False)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1125750 entries, 0 to 1125749\n",
      "Data columns (total 2 columns):\n",
      "description_text     1125750 non-null object\n",
      "harmonized_number    1125750 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_text</th>\n",
       "      <th>harmonized_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>['woodworking', 'machine', 'spare', 'part']</td>\n",
       "      <td>846591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>['woodworking', 'machine', 'spare', 'part', 's...</td>\n",
       "      <td>846591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>['stand', 'throat', 'plate', 'glide', 'pad']</td>\n",
       "      <td>846591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>['garment', 'men', 'soccer', 'sock', 'soccer',...</td>\n",
       "      <td>611595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>['cover', 'connect', 'prestige']</td>\n",
       "      <td>611595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    description_text harmonized_number\n",
       "0        ['woodworking', 'machine', 'spare', 'part']            846591\n",
       "1  ['woodworking', 'machine', 'spare', 'part', 's...            846591\n",
       "2       ['stand', 'throat', 'plate', 'glide', 'pad']            846591\n",
       "3  ['garment', 'men', 'soccer', 'sock', 'soccer',...            611595\n",
       "4                   ['cover', 'connect', 'prestige']            611595"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('final_lemmatized.csv', index=False)\n",
    "df.info()\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
